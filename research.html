<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="">
    <meta name="author" content="Mark Otto, Jacob Thornton, and Bootstrap contributors">
    <meta name="generator" content="Jekyll v3.8.5">
    <title>Research Projects</title>

    <link rel="canonical" href="https://getbootstrap.com/docs/4.3/examples/navbar-fixed/">

    <!-- Bootstrap core CSS -->
<link href="./css/bootstrap.min.css" rel="stylesheet" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
<!--   <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script> -->


    <style>
      .bd-placeholder-img {
        font-size: 1.125rem;
        text-anchor: middle;
        -webkit-user-select: none;
        -moz-user-select: none;
        -ms-user-select: none;
        user-select: none;
      }

      @media (min-width: 768px) {
        .bd-placeholder-img-lg {
          font-size: 3.5rem;
        }
      } 
    </style>
    <!-- Custom styles for this template -->
    <link href="navbar-top-fixed.css" rel="stylesheet">
  </head>
  <body>
<div class="d-flex flex-column flex-md-row align-items-center p-3 px-md-4 mb-3 bg-white border-bottom shadow-sm">
  <nav class="my-2 my-md-0 mr-md-3">
    <a class="p-2 text-dark d-md-inline-block" href="index.html">Home</a>
    <a class="p-2 text-dark d-md-inline-block" href="research.html">Research</a>
    <!--<a class="p-2 text-dark d-md-inline-block" href="group.html">Group</a> -->
    <!--<a class="p-2 text-dark d-md-inline-block" href="teaching.html">Teaching</a> -->
    <!--<a class="p-2 text-dark d-md-inline-block" href="awards.html">Awards</a>-->
    <a class="p-2 text-dark d-md-inline-block" href="prospective.html">Prospective Students</a>
    <!--<a class="p-2 text-dark d-md-inline-block" href="services.html">Services</a> -->
    <!-- <a class="p-2 text-dark d-md-inline-block" href="#">Group</a> -->
  </nav>
</div>

<main role="main" class="container">
      <div><hr></div>

      <div class="starter-template">
        <h2><a id="project"></a>Projects (selected)</h2>
        <div><hr></div>
        <ul class="glyphicon glyphicon-list-alt">


          <li><img src="research_figs/cuszHi.jpg" class="float-right" style="height:120px;margin-right:60px"><b>cuSZ-Hi: Boosting Scientific Error-Bounded Lossy Compression through Optimized Synergistic Lossy-Lossless Orchestration</b> <!--<I><a href="https://arxiv.org/pdf/2312.05492">[Paper Link]</a></I> --> <I><a href="https://github.com/shixun404/cuSZ-Hi">[Code Link]</a></I> 
            <ul class="glyphicon glyphicon-list-alt">
                <li>cuSZ-Hi is a fully open-source high-ratio scientific error-bounded lossy compressor on GPUs.</li>
                <li>Based on cuSZ-I, we further optimized the high-throughput interpolation-based data prediction on GPU platforms, proposing a new scientific data prediction module with multiple interpolation schemes and auto-tuned configurations</li>
                <li>After an in-depth investigation of existing numerical lossless encoders, we craft and incorporate the best-fit lossless encoding pipelines for maximizing the compression ratio on GPUs.</li>
                <li>cuSZ-Hi exhibits outperforming compression ratio and quality compared to all existing state-of-the-arts. It can achieve up to 249% compression ratio improvement over existing scientific lossy compressors under the same error bound and up to 215% compression ratio improvement under the same decompression data PSNR.</li>
                
            </ul>
          </li>
          <br>

          <li><img src="research_figs/qpet.jpg" class="float-right" style="height:120px;margin-right:60px"><b>QPET: A Versatile and Portable Quantity-of-Interest-Preservation Framework for Error-Bounded Lossy Compression</b> <I><a href="https://arxiv.org/pdf/2412.02799">[Paper Link]</a></I>  <I><a href="https://github.com/JLiu-1/QPET-Artifact">[Code Link]</a></I>
            <ul class="glyphicon glyphicon-list-alt">
                <li>QPET is a QoI-oriented Point-wise Error-bound auto-tuning framework to enable the preservation of diverse QoIs in scientific applications.</li>
                <li>QPET leverages numerical and probabilistic methods to derive sufficient error bounds on each data point, which easily adapts to most differentiable QoIs.</li>
                <li>QPET effectively determines the best-fit point-wise error bound for each data value in the QoI-preserving compression. It also jointly optimizes the error-bound storage overhead and the reduction in raw data by a dynamic global error bound selection.</li>
                <li>QPET yields significant compression ratio (CR) and throughput gains in QoI-preserving compression tasks. Under the same QoI error threshold, QPET-integrated compressors achieve up to 1000% CR improvements over the general-purpose compressors and up to 133% CR improvements over existing QoI-preserving lossy compressors. It also achieves 2x to 10x compression speedups over existing QoI-preserving scientific lossy compression solutions.</li>
                
            </ul>
          </li>
          <br>



          <li><img src="research_figs/cuszI.jpg" class="float-right" style="height:120px;margin-right:60px"><b>cuSZ-I: High-Fidelity Error-Bounded Lossy Compression for Scientific Data on GPUs</b> <I><a href="https://arxiv.org/pdf/2312.05492">[Paper Link]</a></I>  <!--<I><a href="https://arxiv.org/pdf/2312.05492">[Code Link]</a></I> -->
            <ul class="glyphicon glyphicon-list-alt">
                <li>We develop a GPU-customized interpolation-based data predictor G-interp with highly parallelized efficient interpolation, which can present excellent data prediction accuracy, thus leading to a high overall compression ratio.</li>
                <li>We design and implement a highly lightweight interpolation auto-tuning kernel for GPU interpolation to optimize both performance and compression quality of cuSZ-I.</li>
                <li>We improve the implementation of GPU-based Huffman encoding and import a new lossless module NVIDIA Bitcomp to further reduce its encoding redundancy.</li>
                <li>cuSZ-I improves compression ratio over other state-of-the-art GPU-based scientific lossy compressors extremely, by up to about 500% under the same error bound or PSNR. Meanwhile, it preserves a compression throughput of the same magnitude as other compressors.</li>
                
            </ul>
          </li>
          <br>

          <li><img src="research_figs/srnn-sz.jpg" class="float-right" style="height:120px;margin-right:60px"><b>SRN-SZ: Scientific Error-bounded Lossy Compression with Super-resolution Neural Networks</b> <I><a href="https://arxiv.org/pdf/2309.04037.pdf">[Paper Link]</a></I> 
            <ul class="glyphicon glyphicon-list-alt">
                <li>We propose a scientific error-bounded lossy compressor SRN-SZ, in which the compression is performed with a hybrid of super-resolution networks and interpolations.</li>
                <li>Leveraging the Hybrid Attention Transformer (HAT) network, we designed a specialized training pipeline with several adaptive techniques to optimize the super-resolution quality of scientific data.</li>
                <li>According to the experimental results, SRN-SZ has achieved up to 75% compression ratio improvements under the same error bound and up to 80% compression ratio improvements under the same PSNR.</li>
                
            </ul>
          </li>
          <br>

          <li><img src="research_figs/QoZ 2.0 framework horizontal.jpg" class="float-right" style="height:120px;margin-right:60px"><b>QoZ 2.0 (HPEZ): High-performance Effective Scientific Error-bounded Lossy Compression with Auto-tuned Multi-component Interpolation</b> <I><a href="https://arxiv.org/pdf/2311.12133.pdf">[Paper Link]</a></I> <I><a href="https://github.com/JLiu-1/HPEZ">[Code Link]</a></I>
            <ul class="glyphicon glyphicon-list-alt">
                <li>Founded on theoretical analysis and algorithmic optimizations, QoZ 2.0 substantially upgrades the most critical step in the quality-oriented compression -- interpolation prediction, leading to an immensely improved data prediction accuracy.</li>
                <li>QoZ 2.0 develops a series of optimization strategies including block-wise interpolation tuning, dynamic dimension freezing, and Lorenzo tuning, which can substantially improve the adaptability of the auto-tuning for the compression across a broad spectrum of inputs.</li>
                <li>QoZ 2.0 significantly outperforms state-of-the-art error-bounded lossy compressors in terms of rate-distortion, while still having a satisfactory speed. It preserves a leading speed compared to other high-ratio compressors. Consequently, it achieves the best throughput in distributed data transfer over WAN based on our experiments. QoZ 2.0 exhibits the least time cost in data transfer for most scientific datasets with up to 40% time reduction.</li>
                
            </ul>
          </li>
          <br>

          <li><img src="research_figs/FAZ_framework.jpg" class="float-right" style="height:120px;margin-right:60px"><b>FAZ: A flexible auto-tuned modular error-bounded compression framework for scientific data</b> <I><a href="https://dl.acm.org/doi/abs/10.1145/3577193.3593721">[Paper Link]</a></I> 
            <ul class="glyphicon glyphicon-list-alt"> 
                <li>FAZ is a flexible and adaptive error-bounded lossy compression framework, which projects a fairly high capability of adapting to diverse datasets.</li>

                <li>FAZ contains different compression modules which having same or similar functionalities, and dynamically selects and auto-tunes the best-fit modules in online compression to establish the optimized compression pipeline for each input data.</li>
                <li>After careful selection of compression techniques and design of pipeline auto-tuning methods, the current version of FAZ is a hybrid-framework leveraing both prediction-based and transform-based compression techniques.</li>
                <li>Experiments show that, compared to the second best compressor, FAZ can improve the compression ratio by up to 120%, 190%, and 75% when setting the same error bound, the same PSNR and the same SSIM, respectively.</li>
            </ul>
          </li>
          <br>

          <li><img src="research_figs/multi-data-distortion.jpg" class="float-right" style="height:120px;margin-right:60px"><b>QoZ: Dynamic Quality Metric Oriented Error Bounded Lossy Compression for Scientific Datasets</b> <I><a href="https://arxiv.org/pdf/2310.14133.pdf">[Paper Link]</a></I> <I><a href="https://github.com/szcompressor/QoZ">[Code Link]</a></I>
            <ul class="glyphicon glyphicon-list-alt">
                <li>QoZ is the first dynamic quality-metric-oriented scientific error-bounded lossy compressor, which can online optimize its compression according to user-specified preferred quality metrics (e.g. PSNR, SSIM, Autocorrelation).</li>
                <li>Based on SZ3 interpolation predictor, QoZ develops and leverages an advanced interpolation-based predictor with high flexibility for auto-tuning, and an effective quality-metric driven auto-tuning algorithm.</li>
                <li>Compared with the second best lossy compressor, QoZ can achieve up to 70% compression ratio improvement under the same error bound, up to 150% compression ratio improvement under the same PSNR, or up to 270% compression ratio improvement under the same SSIM.</li>
                
            </ul>
          </li>
          <br>

          <li><img src="research_figs/aesz.jpg" class="float-right" style="height:120px;margin-right:60px"><b>AE-SZ: Exploring Autoencoder-based Error-bounded Compression for Scientific Data</b>
            <I><a href="https://arxiv.org/pdf/2105.11730.pdf">[Paper Link]</a></I> 
            <ul class="glyphicon glyphicon-list-alt">
                <li>AE-SZ is a deep-learning (autoencoder) based scientific data lossy compressor, which is also a pioneering practice in its time of leveraging deep learning techniques in scientific data compression.</li>
                <li>Like traditional lossy compressors such as SZ, AE-SZ has full support of error-bounding requirements.</li>

                <li>SWAE (Sliced-Wasserstein Autoencoder) and GDN (Generalized Divisive Normalization) is utilized in AE-SZ for generating effective compressed representation of the original input data. The compressed latent vectors are further quantized to maximally improve the compression ratio.</li>

                <li>Based on SZ3 interpolation predictor, QoZ develops and leverages an advanced interpolation-based predictor with high flexibility for auto-tuning, and an effective quality-metric driven auto-tuning algorithm.</li>
                <li>AE-SZ can obtain a much better compression quality (100%-800% improvement in compression ratio with the same data distortion) compared with SZ2.1 and ZFP in cases with high compression ratios.</li>
                
            </ul>
          </li>
        


        </ul>
      </div>
      <div><hr></div>

</main>
<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
      <script>window.jQuery || document.write('<script src="/docs/4.3/assets/js/vendor/jquery-slim.min.js"><\/script>')</script><script src="/docs/4.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-xrRywqdh3PHs8keKZN+8zzc5TX0GRTLCcmivcbNJWm2rs5C8PRhcEn3czEjhAO9o" crossorigin="anonymous"></script></body>
</html>

